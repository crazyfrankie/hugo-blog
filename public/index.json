[
{
  "title": "以日志处理浅谈去中心化",
  "content": "本文通过日志处理的角度来探讨去中心化系统的设计思路和实现方案。\n去中心化系统概述 去中心化是分布式系统设计中的重要概念，它通过将控制权分散到多个节点来提高系统的可靠性和容错性。\n在架构里，“去中心化”不是一定要“完全没有中心”，而是：\n不要有不可替代的单点，而是用 分布式、多对等节点 来分摊职责； 系统的可用性和扩展性 不依赖某一个关键节点。 日志处理 以 ELK 日志处理架构为例，\nELK 介绍 这里简单介绍一下图示结构： ELK 是一种日志处理架构，主要思想是将 AppServer 也就是各个微服务的日志统一使用 LogStash Agent 进行代理收集，经过分析、过滤后发送给远端的 Elastic Search 进行存储， Elastic Search 将数据以分片的形式压缩存储并提供多种 API 供用户查询，操作；用户同样的也可以直观的配置 Kibana Web 方便的对日志查询，并生成数据报表 在传统的中心化系统中，所有的请求都需要通过中央服务器处理，也就是 Server 角色，在本例中也就是 LogStash ，这往往会形成单点故障、集中式的热点问题： …",
  "uri": "/posts/%E4%BB%A5%E6%97%A5%E5%BF%97%E5%A4%84%E7%90%86%E6%B5%85%E8%B0%88%E5%8E%BB%E4%B8%AD%E5%BF%83%E5%8C%96/"
},
{
  "title": "DDD 的一些思考",
  "content": "项目介绍 叠甲，写这篇文章主要是分享在看 DDD 的项目实践中的一些学习感悟，因为本人懒得看理论，所以都只是猜测 DDD 要这么设计。具体还是要参考 DDD 官方网站： DDD 概念介绍\n最近字节开源了它们的 open-coze，前端是 React + TS，后端采用了 Go，刚好没有使用 Py 或者 TS，加上本人对 Go 了解多一点，于是开始学习。\n大致上项目结构是这样的：\n. ├── api ├── application ├── conf ├── crossdomain ├── domain ├── infra ├── internal ├── main.go ├── pkg └── types crossdomain 这里主要讲解 crossdomain 的设计理念，其他的设计跟官网提到的一致，所以可以参考官网。\n当我们遇到 A 模块的某个接口逻辑中涉及到对 B 模块的操作，而同时 B 模块所设计或者说提供的接口不足以满足 A 的要求，一般来说就是数据结构不一致：入参或出参。 所以在简易的设计架构中，有人往往会直接在 B 模块添加方法以满足 A 模块的调用，但这样其实是破坏了 …",
  "uri": "/posts/ddd-%E7%9A%84%E4%B8%80%E4%BA%9B%E6%80%9D%E8%80%83/"
},
{
  "title": "日志与 Error",
  "content": "日志与 Error 一般来说在我们的项目中，按照严格分层的结构划分的话，大致是 handler、service（DDD 中细分为 application 和 domain ），dao。\n对于 dao 层，如果出现错误，我们的处理方式是直接上抛，选择性的打日志处理错误，比如可能有些接口涉及到在 dao层进行参数校验、手动管理事务等，需要日志记录，但错误仍然是直接上抛。\n在 service层，我们遇到错误时，分为两种情况：业务预期内的错误、非业务错误。\n对于前者，我们的处理方式是，预先定义各种业务错误码， 在遇到时将其转换为 error 接口上抛，由 handler 转换为 resp code 返回给客户端，可选 Warn 日志（低频关键场景）。\n对于后者，错误通常是技术错误，不应由service 自身处理，而是交由调用方处理，那么我们在这里是打日志+错误上抛。这里的描述也不详尽，具体的可以参考下表：\n场景分类 处理方式 日志策略 是否向上抛 示例 1. 预期内的业务错误 返回自定义业务错误类型 可选Warn日志（低频关键场景） 是 ErrUserNotFound 2. …",
  "uri": "/posts/%E6%97%A5%E5%BF%97%E4%B8%8E-error/"
},
{
  "title": "DB-Cache 一致性问题",
  "content": "如何保证缓存和数据库一致性，这是一个老生常谈的话题了。\n但很多人对这个问题，依旧有很多疑惑：\n到底是更新缓存还是删缓存？ 到底选择先更新数据库，再删除缓存，还是先删除缓存，再更新数据库？ 为什么要引入消息队列保证一致性？ 延迟双删会有什么问题？到底要不要用？ … 引入缓存提高性能 我们从最简单的场景开始讲起。\n如果你的业务处于起步阶段，流量非常小，那无论是读请求还是写请求，直接操作数据库即可，这时你的架构模型是这样的：\n但随着业务量的增长，你的项目请求量越来越大，这时如果每次都从数据库中读数据，那肯定会有性能问题。\n这个阶段通常的做法是，引入「缓存」来提高读性能，架构模型就变成了这样：\n当下优秀的缓存中间件，当属 Redis 莫属，它不仅性能非常高，还提供了很多友好的数据类型，可以很好地满足我们的业务需求。\n但引入缓存之后，你就会面临一个问题：之前数据只存在数据库中，现在要放到缓存中读取，具体要怎么存呢？\n最简单直接的方案是「全量数据刷到缓存中」：\n数据库的数据，全量刷入缓存（不设置失效时间） 写请求只更新数据库，不更新缓存 启动一个定时任务，定时把数据库的数据，更新到缓存中 这个方案 …",
  "uri": "/posts/db-cache-%E4%B8%80%E8%87%B4%E6%80%A7%E9%97%AE%E9%A2%98/"
},
{
  "title": "MVCC 及 MySQL 日志",
  "content": "在 MVCC 机制下，Redo Log 和 Bin Log 主要在事务提交时发挥作用 ，它们的作用和触发时机如下：\n事务执行过程中的日志行为 当执行：\nUPDATE users SET age = 26 WHERE id = 1; MySQL 的 事务执行顺序 （结合 MVCC + 日志）如下：\n(1) 生成 Undo Log（历史版本） MVCC 机制 ： 事务修改 age 字段时，不直接覆盖，而是将旧值写入 Undo Log （用于回滚和快照读）。 假设 age 原来是 25，Undo Log 记录： { trx_id: 1001, row_id: 1, old_value: 25 } 在 Buffer Pool 中修改 age = 26 ，但其他事务可能仍然看到 25（基于 Undo Log）。 (2) 写入 Redo Log（保证崩溃恢复） MySQL 不直接将数据写入磁盘，而是先记录 Redo Log（WAL 机制） ： Redo Log 记录物理层面的修改： yaml复制编辑{ page_id: 123, offset: 56, new_value: 26, state: …",
  "uri": "/posts/mvcc-%E5%8F%8A-mysql-%E6%97%A5%E5%BF%97/"
},
{
  "title": "负载均衡",
  "content": "概览 在分布式环境下，各个微服务都会有不同的实例，服务注册和服务发现解决了“有哪些可用实例”的问题，剩下面临的就是，“这么多可用实例，我该把请求发给谁？”。直觉来说，大部分人如果听过一些专业名词，此时会直接想到“负载均衡”。那负载均衡到底是什么呢？\n负载均衡是在支持应用程序的资源池中平均分配网络流量的一种方法。现代应用程序必须同时处理数百万用户，并以快速、可靠的方式将正确的文本、视频、图像和其他数据返回给每个用户。为了处理如此高的流量，大多数应用程序都有许多资源服务器，它们之间包含很多重复数据。负载均衡器是位于用户与服务器组之间的设备，充当不可见的协调者，确保均等使用所有资源服务器。 —— aws\n事实上负载均衡是手段而不是目的。因此从目的上来说，我们其实不需要搞什么负载均衡，我们的目的就是把请求转发给“最适合”处理这个请求的节点。最适合意味着：\n– 如果这个请求需要很多内存，那么将它转发给内存多的节点。\n– 如果这个请求是 CPU 密集的，那么将它转发给 CPU 比较空闲的请求。\n– ……\n显然，在大多数时候，我们会希望将请求转发给“能够最快返回响应”的那个节点。\n负载均衡的本质 在 …",
  "uri": "/posts/%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/"
},
{
  "title": "感悟",
  "content": "人的肉体是过去，意识是现在和未来。\n",
  "uri": "/posts/%E6%84%9F%E6%82%9F/"
}]
